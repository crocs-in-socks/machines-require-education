{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE LINEAR REGRESSION MODEL :\n",
    "\n",
    "In a linear model, we try to fit a straight line to our training data, and then we make use of this line to predict future values. In linear regression specifically, we make use of gradient descent to determine the best fit line to our training data.\n",
    "\n",
    "This model as the name suggests, solves regression problems.\n",
    "\n",
    "In standard machine learning notation :\n",
    "\n",
    "x = input variable or input feature\n",
    "\n",
    "y = output variable or target variable\n",
    "\n",
    "m = total number of training example\n",
    "\n",
    "(x, y) = single training example\n",
    "\n",
    "$ (x^{(i)}, y^{(i)})$ represents the ith training example\n",
    "\n",
    "$ \\hat{y} $ is the prediction produced by the model's function when given an input feature.\n",
    "\n",
    "In linear regression, as we try to fit a straight line, we represent the function as :\n",
    "    $f_{w, b}$ (x) = wx+b // For linear regression with one variable\n",
    "\n",
    "Here, w and b are called the parameters of the problem. These are the variables that we can adjust during training the model. They are also sometimes called co-efficients or weights.\n",
    "\n",
    "The cost function of this model is the average squared error sum of every training example in the training set.The cost function is represented by J(w, b).\n",
    "\n",
    "The cost function used is :\n",
    "$\n",
    "\\frac{1}{2m}\\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})^{2}\n",
    "$\n",
    "\n",
    "Our model's objective now becomes the minimization of J, as it represents how wrong the prediction might be. We can minimize J by changing the values of w and b.\n",
    "\n",
    "We use the technique of gradient descent to minimize our cost function.\n",
    "\n",
    "GRADIENT DESCENT :\n",
    "\n",
    "Gradient descent can be used to minimize any function with any number of parameters, and here we use it to minimize our cost function. The outline of this algorithm is:\n",
    "- We first set some initial values for our parameters. Here we set w = 0 and b = 0.\n",
    "- Then we keep changing w, and b to reduce J(w, b) until we settle either at or near a minimum.\n",
    "\n",
    "One drawback of this algorithm is that the minima we end up at can be affected by our arbitrarily chosen starting position.\n",
    "\n",
    "This is not an issue as in the cost function there is only one global minimum.\n",
    "\n",
    "The formula for gradient descent is : \n",
    "\n",
    "$\n",
    "w = w - \\alpha \\frac{\\partial}{\\partial w}J(w, b)\n",
    "$\n",
    "\n",
    "$\n",
    "b = b - \\alpha \\frac{\\partial}{\\partial b}J(w, b)\n",
    "$\n",
    "\n",
    "We continue the above steps until we converge at a local minimum, that is, until w and b do not change by much with each iteration. We must also make sure to update both w and b *simultaneously*.\n",
    "\n",
    "$\\alpha$ in the above formulae represents the learning rate of the algorithm and has to be carefully balanced.\n",
    "\n",
    "If $\\alpha$ is too small, the algorithm takes too long, and may never converge. If it is too large, the algorithm may overshoot and then diverge.\n",
    "\n",
    "On applying the gradient descent formulae to our cost function we get :\n",
    "\n",
    "$\n",
    "w = w - \\alpha \\frac{1}{m} \\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})x^{(i)}\n",
    "$\n",
    "\n",
    "$\n",
    "b = b - \\alpha \\frac{1}{m} \\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})\n",
    "$\n",
    "\n",
    "We're using \"Batch\" gradient descent, here each step of gradient descent uses all the training examples.\n",
    "\n",
    "OPTIMIZING GRADIENT DESCENT :\n",
    "\n",
    "Considering our model now makes use of multiple features. Here $x_{j}$ denotes the jth features and n denotes the number of features. We also update our model's function. This is now : \n",
    "\n",
    "$ f_{w, b}(x) = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + ... + w_{n}x_{n} + b $\n",
    "\n",
    "This represents multiple linear regression, not multivariate regression which means something else.\n",
    "\n",
    "We take w as a vector that consists of all the weights $w_{1}$ to $w_{n}$ and x as a vector that consists of all parameters $x_{1}$ to $x_{n}$. Then we can make use of factorization to solve for the minimum of the cost function.\n",
    "\n",
    "For multiple parameters, we update them simultaneously as : \n",
    "\n",
    "$\n",
    "w_{n} = w_{n} - \\alpha \\frac{1}{m} \\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})x_{n}^{(i)}\n",
    "$\n",
    "\n",
    "In the case of linear regression, instead of using gradient descent, we can use the normal equation to find the minimum cost function.\n",
    "\n",
    "The normal equation method is not an iterative version. It takes only one step. However this method is slow when the number of features is large.\n",
    "\n",
    "FEATURE SCALING : \n",
    "\n",
    "This is another method used to make gradient descent faster.\n",
    "\n",
    "If the range of a parameter is relatively small, then if the value of its weight is relatively larger, we find that our model will give more accurate results. This is also the case when the range of our parameter is relatively smaller and the value of its weight is relatively larger.\n",
    "\n",
    "In such situations, we generally scale our features, so that the ranges of our parameters are about the same. This can be done in three ways. We either, divide all elements by the maximum value, perform mean-normalization(subtract mean from every value then divide by class interval), or perform Z-score scaling(subtact by mean and then divide by standard deviation).\n",
    "\n",
    "It is a good idea to scale features that have either very large ranges or very small ranges. A good range typically lies between -3 and 3.\n",
    "\n",
    "HOW TO MAKE SURE GRADIENT DESCENT IS CONVERGING :\n",
    "\n",
    "We can tell that gradient descent has generally converges where the plot of cost function J vs the number of iterations run levels out. If the cost increases at any point of the graph, we have either chosen the learning rate poorly or there's a bug in the code somewhere.\n",
    "\n",
    "CHOOSING APPROPRIATE FEATURES : \n",
    "\n",
    "Here, we use intuition to design new features generally by transforming or combining original features.\n",
    "\n",
    "POLYNOMIAL REGRESSION : \n",
    "\n",
    "Depending on how the output values and input values behave with each other, we may decide that a quadratic or cubic function would fit our data better. In this case, we simply use the square or cube of our parameters respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "J_{w, b} = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})^{2} + \\frac{\\lambda}{2m}\\sum\\limits_{j=1}^{m}w_{j}^{2}\n",
    "$\n",
    "\n",
    "This is the cost function for regularized linear regression. With the regularization term, the formula for gradient descent changes as :\n",
    "\n",
    "$\n",
    "w_{j} = w_{j} - \\alpha [\\frac{1}{m} \\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})x^{(i)} + \\frac{\\lambda}{m}w_{j}]\n",
    "$\n",
    "\n",
    "$\n",
    "b = b - \\alpha \\frac{1}{m} \\sum \\limits_{i=1}^{m}(f_{w, b}(x^{(i)}) - y^{(i)})\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
